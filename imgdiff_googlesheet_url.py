#!/usr/bin/env python3
"""
êµ¬ê¸€ ì‹œíŠ¸ URL ê¸°ë°˜ ì´ë¯¸ì§€ ë¹„êµ ë„êµ¬
IMAGE í•¨ìˆ˜ì˜ URLì„ ì¶”ì¶œí•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¹„êµí•©ë‹ˆë‹¤.
"""

import os
import sys
import csv
import pickle
import re
import requests
import tempfile
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import argparse
from datetime import datetime
from urllib.parse import urlparse, parse_qs

# Google Sheets API
try:
    from google.auth.transport.requests import Request
    from google.oauth2.credentials import Credentials
    from google_auth_oauthlib.flow import InstalledAppFlow
    from googleapiclient.discovery import build
    from googleapiclient.errors import HttpError
except ImportError:
    print("êµ¬ê¸€ ì‹œíŠ¸ API ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
    print("pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib")
    sys.exit(1)

from imgdiff import ImageComparator


class GoogleSheetURLImageComparator:
    """êµ¬ê¸€ ì‹œíŠ¸ì˜ IMAGE í•¨ìˆ˜ URLì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¹„êµ í´ë˜ìŠ¤"""

    SCOPES = ['https://www.googleapis.com/auth/spreadsheets']

    def __init__(self, spreadsheet_id: str, range_name: str = 'B3:C',
                 output_dir: str = 'googlesheet_url_results',
                 threshold: int = 20, morphology_kernel_size: int = 3,
                 blur_kernel_size: int = 0):
        self.spreadsheet_id = spreadsheet_id
        self.range_name = range_name
        self.output_dir = output_dir
        self.threshold = threshold
        self.morphology_kernel_size = morphology_kernel_size
        self.blur_kernel_size = blur_kernel_size
        self.service = None
        self.results = []
        self.temp_dir = None

    def authenticate(self, credentials_file: str = 'credentials.json'):
        """êµ¬ê¸€ ì‹œíŠ¸ API ì¸ì¦"""
        creds = None

        if os.path.exists('token.pickle'):
            with open('token.pickle', 'rb') as token:
                creds = pickle.load(token)

        if not creds or not creds.valid:
            if creds and creds.expired and creds.refresh_token:
                creds.refresh(Request())
            else:
                if not os.path.exists(credentials_file):
                    print(f"âŒ ì¸ì¦ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {credentials_file}")
                    sys.exit(1)

                flow = InstalledAppFlow.from_client_secrets_file(
                    credentials_file, self.SCOPES)
                creds = flow.run_local_server(port=0)

            with open('token.pickle', 'wb') as token:
                pickle.dump(creds, token)

        self.service = build('sheets', 'v4', credentials=creds)
        print("âœ… êµ¬ê¸€ ì‹œíŠ¸ API ì¸ì¦ ì„±ê³µ")

    def extract_url_from_image(self, cell_value: str) -> Optional[str]:
        """IMAGE í•¨ìˆ˜ì—ì„œ URL ì¶”ì¶œ"""
        if not cell_value:
            return None

        # =IMAGE("URL") ë˜ëŠ” =IMAGE('URL') íŒ¨í„´
        patterns = [
            r'=IMAGE\s*\(\s*"([^"]+)"\s*\)',
            r"=IMAGE\s*\(\s*'([^']+)'\s*\)"
        ]

        for pattern in patterns:
            match = re.match(pattern, str(cell_value), re.IGNORECASE)
            if match:
                return match.group(1)

        # IMAGE í•¨ìˆ˜ê°€ ì•„ë‹ˆë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬ (URLì¸ ê²½ìš°)
        if cell_value.startswith('http'):
            return cell_value

        return None

    def download_image(self, url: str, filename: str) -> Optional[str]:
        """URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ"""
        try:
            print(f"  ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {filename}")

            # í—¤ë” ì„¤ì • (User-Agent ì¶”ê°€)
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }

            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()

            # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥
            if not self.temp_dir:
                self.temp_dir = tempfile.mkdtemp(prefix='imgdiff_')

            filepath = os.path.join(self.temp_dir, filename)
            with open(filepath, 'wb') as f:
                f.write(response.content)

            print(f"  âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filename}")
            return filepath

        except requests.RequestException as e:
            print(f"  âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def read_sheet_urls(self) -> List[Dict]:
        """êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ IMAGE í•¨ìˆ˜ì˜ URL ì½ê¸°"""
        if not self.service:
            raise Exception("ë¨¼ì € authenticate() ë©”ì„œë“œë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

        try:
            # ìˆ˜ì‹ ê°€ì ¸ì˜¤ê¸° (IMAGE í•¨ìˆ˜ í¬í•¨)
            result = self.service.spreadsheets().values().get(
                spreadsheetId=self.spreadsheet_id,
                range=self.range_name,
                valueRenderOption='FORMULA'  # ìˆ˜ì‹ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ê¸°
            ).execute()

            values = result.get('values', [])

            if not values:
                print('âš ï¸  ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.')
                return []

            print(f"âœ… {len(values)}ê°œì˜ í–‰ì„ ì½ì—ˆìŠµë‹ˆë‹¤.")

            url_pairs = []
            for idx, row in enumerate(values, 3):  # B3ë¶€í„° ì‹œì‘
                if len(row) >= 2:
                    url1 = self.extract_url_from_image(row[0])
                    url2 = self.extract_url_from_image(row[1])

                    if url1 and url2:
                        # URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
                        name1 = self.extract_filename_from_url(url1)
                        name2 = self.extract_filename_from_url(url2)

                        url_pairs.append({
                            'row': idx,
                            'url1': url1,
                            'url2': url2,
                            'name1': name1,
                            'name2': name2,
                            'name': f"{name1}_vs_{name2}"
                        })

            print(f"ğŸ”— {len(url_pairs)}ê°œì˜ URL ìŒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
            return url_pairs

        except HttpError as err:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {err}")
            return []

    def extract_filename_from_url(self, url: str) -> str:
        """URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ"""
        parsed = urlparse(url)
        path = parsed.path
        filename = os.path.basename(path)

        # íŒŒì¼ëª…ì´ ì—†ìœ¼ë©´ URLì˜ ì¼ë¶€ë¥¼ ì‚¬ìš©
        if not filename or filename == '/':
            # ê²½ë¡œì˜ ë§ˆì§€ë§‰ ë‘ ë¶€ë¶„ì„ ì¡°í•©
            parts = [p for p in path.split('/') if p]
            if len(parts) >= 2:
                filename = f"{parts[-2]}_{parts[-1]}"
            else:
                filename = "image"

        # í™•ì¥ìê°€ ì—†ìœ¼ë©´ .png ì¶”ê°€
        if '.' not in filename:
            filename += '.png'

        return filename

    def compare_url_images(self, url_pairs: List[Dict]) -> List[Dict]:
        """URL ì´ë¯¸ì§€ ìŒì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ë¹„êµ"""
        results = []
        total = len(url_pairs)

        os.makedirs(self.output_dir, exist_ok=True)

        for idx, pair in enumerate(url_pairs, 1):
            print(f"\n[{idx}/{total}] ë¹„êµ ì¤‘: í–‰ {pair['row']}")
            print(f"  URL1: {pair['url1'][:80]}...")
            print(f"  URL2: {pair['url2'][:80]}...")

            result = {
                'row': pair['row'],
                'name': pair['name'],
                'url1': pair['url1'],
                'url2': pair['url2'],
                'status': 'pending'
            }

            try:
                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                img1_path = self.download_image(pair['url1'], f"row{pair['row']}_img1_{pair['name1']}")
                img2_path = self.download_image(pair['url2'], f"row{pair['row']}_img2_{pair['name2']}")

                if not img1_path or not img2_path:
                    raise Exception("ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

                # ì´ë¯¸ì§€ ë¹„êµ
                comparator = ImageComparator(img1_path, img2_path)

                # ì›ë³¸ í†µê³„ (í•„í„°ë§ ì—†ìŒ)
                stats_original = comparator.get_statistics(threshold=self.threshold)

                # ì²˜ë¦¬ëœ í†µê³„ (OpenCV í•„í„°ë§ ì ìš© - ì‹¤ì œ í‘œì‹œë˜ëŠ” ê²ƒê³¼ ì¼ì¹˜)
                stats_processed = comparator.get_processed_statistics(
                    threshold=self.threshold,
                    morphology_kernel_size=self.morphology_kernel_size,
                    blur_kernel_size=self.blur_kernel_size
                )

                # resultì—ëŠ” ì²˜ë¦¬ëœ í†µê³„ ì‚¬ìš© (ì‹¤ì œ ì´ë¯¸ì§€ì™€ ì¼ì¹˜)
                result.update({
                    'status': 'success',
                    'diff_percentage': stats_processed['diff_percentage'],
                    'changed_pixels': stats_processed['changed_pixels'],
                    'changed_percentage': stats_processed['changed_percentage'],
                    'image_size': comparator.img1.size
                })

                # ê²°ê³¼ ì €ì¥
                row_dir = os.path.join(self.output_dir, f"row_{pair['row']}")
                os.makedirs(row_dir, exist_ok=True)

                # ì°¨ì´ ì´ë¯¸ì§€ ì €ì¥ (í˜•íƒœí•™ì  ì—°ì‚° ì ìš©)
                diff_img = comparator.create_diff_image(
                    'highlight',
                    threshold=self.threshold,
                    morphology_kernel_size=self.morphology_kernel_size,
                    blur_kernel_size=self.blur_kernel_size
                )
                diff_img.save(os.path.join(row_dir, 'diff_highlight.png'))

                # ë‚˜ë€íˆ ë¹„êµ ì´ë¯¸ì§€ ì €ì¥ (ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„° ì ìš©)
                side_by_side_path = os.path.join(row_dir, 'side_by_side.png')
                comparator.create_side_by_side_comparison(
                    side_by_side_path,
                    threshold=self.threshold,
                    morphology_kernel_size=self.morphology_kernel_size,
                    blur_kernel_size=self.blur_kernel_size
                )

                # í†µê³„ ì •ë³´ JSONìœ¼ë¡œ ì €ì¥
                import json
                import numpy as np

                # NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                def convert_numpy(obj):
                    if isinstance(obj, np.integer):
                        return int(obj)
                    elif isinstance(obj, np.floating):
                        return float(obj)
                    elif isinstance(obj, np.ndarray):
                        return obj.tolist()
                    elif isinstance(obj, dict):
                        return {k: convert_numpy(v) for k, v in obj.items()}
                    elif isinstance(obj, (list, tuple)):
                        return [convert_numpy(item) for item in obj]
                    return obj

                # ë‘ ê°€ì§€ í†µê³„ë¥¼ ëª¨ë‘ ì €ì¥
                combined_stats = {
                    'original': convert_numpy(stats_original),
                    'processed': convert_numpy(stats_processed),
                    'note': 'The "processed" statistics match the red highlighted areas in diff_highlight.png. "original" statistics are based on raw pixel differences without filtering.'
                }

                stats_path = os.path.join(row_dir, 'stats.json')
                with open(stats_path, 'w', encoding='utf-8') as f:
                    json.dump(combined_stats, f, indent=2, ensure_ascii=False)

                print(f"  âœ… ì„±ê³µ: ì°¨ì´ìœ¨ {stats_processed['diff_percentage']:.2f}% (ì²˜ë¦¬ í›„: {stats_processed['changed_percentage']:.2f}%)")

            except Exception as e:
                result.update({
                    'status': 'error',
                    'error_message': str(e)
                })
                print(f"  âŒ ì‹¤íŒ¨: {e}")

            results.append(result)

        self.results = results
        return results

    def update_sheet_results(self, start_column: str = 'D', start_row: int = 3):
        """ë¹„êµ ê²°ê³¼ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì— ì—…ë°ì´íŠ¸"""
        if not self.service or not self.results:
            return

        update_values = []
        for result in self.results:
            if result['status'] == 'success':
                row_data = [
                    'ì„±ê³µ',
                    f"{result['diff_percentage']:.2f}%",
                    f"{result['changed_percentage']:.2f}%",
                    f"{result.get('image_size', '')}",
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                ]
            else:
                row_data = [
                    'ì‹¤íŒ¨',
                    '',
                    '',
                    result.get('error_message', ''),
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                ]
            update_values.append(row_data)

        # ì²« ë²ˆì§¸ ê²°ê³¼ì˜ í–‰ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        if self.results:
            first_row = self.results[0]['row']
            last_row = first_row + len(self.results) - 1
            update_range = f"{start_column}{first_row}:{chr(ord(start_column)+4)}{last_row}"

            try:
                body = {'values': update_values}
                result = self.service.spreadsheets().values().update(
                    spreadsheetId=self.spreadsheet_id,
                    range=update_range,
                    valueInputOption='USER_ENTERED',
                    body=body
                ).execute()

                print(f"âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {result.get('updatedCells')}ê°œ ì…€")

                # í—¤ë” ì¶”ê°€
                if first_row > 1:
                    header_range = f"{start_column}{first_row-1}:{chr(ord(start_column)+4)}{first_row-1}"
                    header_body = {
                        'values': [['ìƒíƒœ', 'ì°¨ì´ìœ¨', 'ë³€ê²½í”½ì…€', 'ë¹„ê³ ', 'ì²˜ë¦¬ì‹œê°„']]
                    }
                    self.service.spreadsheets().values().update(
                        spreadsheetId=self.spreadsheet_id,
                        range=header_range,
                        valueInputOption='USER_ENTERED',
                        body=header_body
                    ).execute()

            except HttpError as err:
                print(f"âŒ ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {err}")

    def cleanup_temp_files(self):
        """ì„ì‹œ íŒŒì¼ ì •ë¦¬"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            import shutil
            shutil.rmtree(self.temp_dir)
            print("ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")

    def generate_report(self):
        """ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not self.results:
            return

        print("\n" + "="*60)
        print("ë¹„êµ ì™„ë£Œ ìš”ì•½")
        print("="*60)

        success = sum(1 for r in self.results if r['status'] == 'success')
        error = sum(1 for r in self.results if r['status'] == 'error')

        print(f"ì „ì²´: {len(self.results)}ê°œ")
        print(f"ì„±ê³µ: {success}ê°œ")
        print(f"ì‹¤íŒ¨: {error}ê°œ")

        if success > 0:
            avg_diff = sum(r['diff_percentage'] for r in self.results if r['status'] == 'success') / success
            print(f"í‰ê·  ì°¨ì´ìœ¨: {avg_diff:.2f}%")

        # CSV ì €ì¥
        csv_path = os.path.join(self.output_dir, 'url_results.csv')
        with open(csv_path, 'w', encoding='utf-8', newline='') as f:
            fieldnames = ['row', 'status', 'diff_percentage', 'changed_percentage', 'url1', 'url2']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()

            for result in self.results:
                writer.writerow({
                    'row': result.get('row'),
                    'status': result.get('status'),
                    'diff_percentage': result.get('diff_percentage', ''),
                    'changed_percentage': result.get('changed_percentage', ''),
                    'url1': result.get('url1', ''),
                    'url2': result.get('url2', '')
                })

        print(f"\nğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {self.output_dir}")


def main():
    parser = argparse.ArgumentParser(description='êµ¬ê¸€ ì‹œíŠ¸ URL ê¸°ë°˜ ì´ë¯¸ì§€ ë¹„êµ')
    parser.add_argument('spreadsheet_id', help='êµ¬ê¸€ ì‹œíŠ¸ ID')
    parser.add_argument('--range', default='B3:C',
                       help='ì½ì„ ë²”ìœ„ (ê¸°ë³¸ê°’: B3:C)')
    parser.add_argument('--output-dir', default='googlesheet_url_results',
                       help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--update-sheet', action='store_true',
                       help='ê²°ê³¼ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì— ì—…ë°ì´íŠ¸')
    parser.add_argument('--threshold', type=int, default=30,
                       help='ì°¨ì´ ê°ì§€ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 30, ë†’ì„ìˆ˜ë¡ ë¯¼ê°ë„ ë‚®ìŒ)')
    parser.add_argument('--morphology-kernel-size', type=int, default=3,
                       help='í˜•íƒœí•™ì  ì—°ì‚° ì»¤ë„ í¬ê¸° (ê¸°ë³¸ê°’: 3, 0ì´ë©´ ë¹„í™œì„±í™”)')
    parser.add_argument('--blur-kernel-size', type=int, default=0,
                       help='ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ì»¤ë„ í¬ê¸° (ê¸°ë³¸ê°’: 0, 0ì´ë©´ ë¹„í™œì„±í™”)')

    args = parser.parse_args()

    comparator = GoogleSheetURLImageComparator(
        args.spreadsheet_id,
        args.range,
        args.output_dir,
        threshold=args.threshold,
        morphology_kernel_size=args.morphology_kernel_size,
        blur_kernel_size=args.blur_kernel_size
    )

    try:
        # ì¸ì¦
        comparator.authenticate()

        # URL ì½ê¸°
        url_pairs = comparator.read_sheet_urls()

        if not url_pairs:
            print("âš ï¸  ì²˜ë¦¬í•  URL ìŒì´ ì—†ìŠµë‹ˆë‹¤.")
            return 1

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë¹„êµ
        comparator.compare_url_images(url_pairs)

        # ë¦¬í¬íŠ¸ ìƒì„±
        comparator.generate_report()

        # êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸
        if args.update_sheet:
            comparator.update_sheet_results()

    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        comparator.cleanup_temp_files()

    return 0


if __name__ == '__main__':
    exit(main())